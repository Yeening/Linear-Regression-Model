{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning HW1\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "# more imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the file and return 2 numpy arrays\n",
    "def load_data_set(filename):\n",
    "    # your code\n",
    "    return x, y\n",
    "\n",
    "# Find theta using the normal equation\n",
    "def normal_equation(x, y):\n",
    "    # your code\n",
    "    return theta\n",
    "\n",
    "# Find thetas using stochiastic gradient descent\n",
    "# Don't forget to shuffle\n",
    "def stochiastic_gradient_descent(x, y, learning_rate, num_iterations):\n",
    "    # your code\n",
    "    return thetas\n",
    "\n",
    "# Find thetas using gradient descent\n",
    "def gradient_descent(x, y, learning_rate, num_iterations):\n",
    "    # your code\n",
    "    return thetas\n",
    "\n",
    "# Find thetas using minibatch gradient descent\n",
    "# Don't forget to shuffle\n",
    "def minibatch_gradient_descent(x, y, learning_rate, num_iterations, batch_size):\n",
    "    # your code\n",
    "    return thetas\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given an array of x and theta predict y\n",
    "def predict(x, theta):\n",
    "   # your code\n",
    "   return y_predict\n",
    "\n",
    "# Given an array of y and y_predict return loss\n",
    "def get_loss(y, y_predict):\n",
    "    # your code\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a list of thetas one per epoch\n",
    "# this creates a plot of epoch vs training error\n",
    "def plot_training_errors(x, y, thetas, title):\n",
    "    losses = []\n",
    "    epochs = []\n",
    "    losses = []\n",
    "    epoch_num = 1\n",
    "    for theta in thetas:\n",
    "        losses.append(get_loss(y, predict(x, theta)))\n",
    "        epochs.append(epoch_num)\n",
    "        epoch_num += 1\n",
    "    plt.plot(epochs, losses)\n",
    "    plt.xlabel(\"epoch\")\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "# Given x, y, y_predict and title,\n",
    "# this creates a plot\n",
    "def plot(x, y, theta, title):\n",
    "    # plot\n",
    "    y_predict = predict(x, theta)\n",
    "    plt.scatter(x[:, 1], y)\n",
    "    plt.plot(x[:, 1], y_predict)\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-b70a85a82edd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'regression-data.txt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;31m# plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-401e912816ca>\u001b[0m in \u001b[0;36mload_data_set\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_data_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;31m# your code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Find theta using the normal equation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    x, y = load_data_set('regression-data.txt')\n",
    "    # plot\n",
    "    plt.scatter(x[:, 1], y)\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.title(\"Scatter Plot of Data\")\n",
    "    plt.show()\n",
    "\n",
    "    theta = normal_equation(x, y)\n",
    "    plot(x, y, theta, \"Normal Equation Best Fit\")\n",
    "\n",
    "    # You should try multiple non-zero learning rates and  multiple different (non-zero) number of iterations\n",
    "    thetas = gradient_descent(x, y, 0, 0) \n",
    "    plot(x, y, thetas[-1], \"Gradient Descent Best Fit\")\n",
    "    plot_training_errors(x, y, thetas, \"Gradient Descent Mean Epoch vs Training Loss\")\n",
    "\n",
    "    # You should try multiple non-zero learning rates and  multiple different (non-zero) number of iterations\n",
    "    thetas = stochiastic_gradient_descent(x, y, 0, 0) # Try different learning rates and number of iterations\n",
    "    plot(x, y, thetas[-1], \"Stochiastic Gradient Descent Best Fit\")\n",
    "    plot_training_errors(x, y, thetas, \"Stochiastic Gradient Descent Mean Epoch vs Training Loss\")\n",
    "\n",
    "    # You should try multiple non-zero learning rates and  multiple different (non-zero) number of iterations\n",
    "    thetas = minibatch_gradient_descent(x, y, 0, 0, 0)\n",
    "    plot(x, y, thetas[-1], \"Minibatch Gradient Descent Best Fit\")\n",
    "    plot_training_errors(x, y, thetas, \"Minibatch Gradient Descent Mean Epoch vs Training Loss\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml3.7",
   "language": "python",
   "name": "ml3.7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
